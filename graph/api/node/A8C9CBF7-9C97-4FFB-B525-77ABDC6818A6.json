{
  "id": "A8C9CBF7-9C97-4FFB-B525-77ABDC6818A6",
  "title": "2025年12月 個人的claude codeワークフロー",
  "raw": ":PROPERTIES:\n:ID:       A8C9CBF7-9C97-4FFB-B525-77ABDC6818A6\n:END:\n#+TITLE: 2025年12月 個人的claude codeワークフロー\n#+AUTHOR: takeokunn\n#+DESCRIPTION: Claude Codeをマルチエージェントシステムとして活用するためのカスタマイズ手法\n#+DATE: 2025-12-30T10:42:44+0900\n#+HUGO_BASE_DIR: ../../\n#+HUGO_CATEGORIES: permanent\n#+HUGO_SECTION: posts/permanent\n#+HUGO_TAGS: permanent ai\n#+HUGO_DRAFT: false\n#+STARTUP: fold\n* 1. はじめに\n\nClaude Codeを本格的に使い始めました。\n\n最初はGitHub Copilotと同じ感覚で、コード生成ツールの延長として使っていたのですが、あるとき気づきました。「セキュリティレビューをお願いしたら、コードスタイルの指摘ばかり返ってきた」「昨日と同じ質問をしたのに、まったく違うフォーマットで回答された」「プロジェクトの規約を毎回説明するのが面倒」。これ、Claude Codeの問題じゃなくて、自分の使い方の問題でした。\n\n試行錯誤を重ねるうちに、Claude Codeは単なるコード補完ツールではなく、適切に設定すればマルチエージェントシステムとして機能することに気づきました。\n\nこの記事では、構築したワークフローを共有します。\n\nちなみに、この記事も大半はClaude Codeに書いてもらいました。\n\n* 2. 背景と設計哲学\n** 2.1. 感じていた課題\n\nClaude Codeを本格的に使い始める前、いくつかの課題を感じていました。\n\n一番大きかったのは専門性の欠如です。単一のAIエージェントでは、コード品質・セキュリティ・テスト・ドキュメントなど複数のドメインにまたがるタスクをうまく処理できませんでした。セキュリティの観点でレビューをお願いしても、コードスタイルの指摘が混在して、本当に確認したいポイントが埋もれてしまいます。\n\n出力の不安定性も悩みの種でした。構造化されたプロンプトなしでは、AIの応答品質やフォーマットが毎回異なります。昨日と同じ質問をしても、回答の形式がまったく違うということがよくありました。\n\n繰り返しの説明にも時間を取られていました。同じパターンや好みを何度もAIに説明する必要があり、徒労感がありました。\n\n** 2.2. 5つのルール\n\nCLAUDE.mdには5つの =critical= ルールを定義しています。この5つが私のワークフローの根幹になっています。\n\n1. サブエージェントへの委譲 : 親エージェントは方針決定とオーケストレーションに集中し、詳細な作業は専門エージェントに任せる\n2. Serenaメモリの事前確認 : 実装前に必ず =list_memories= と =read_memory= でプロジェクトの規約やパターンを確認する\n3. シンボルレベルの操作 : ファイル全体を読み込むのではなく、Serenaの =find_symbol= などでシンボル単位で操作する\n4. perlでテキスト処理 : sed/awkは使わない。 =perl -pe 's/foo/bar/g'= で統一\n5. 英語で出力 : 出力は常に英語に統一\n\nなぜこの5つなのか。1と2はマルチエージェント構成の核心、3はトークン効率の改善、4と5は出力の一貫性を担保するためです。\n\n* 3. プロンプト設計の基盤\n\nここで紹介するプロンプトの多くは、Claude Code自身に生成させました。「こういう形式で書いて」と伝えて、その出力を調整しながら現在の形に至りました。\n\nClaude Codeのプロンプトは構造化されたXMLで記述しています。\n\n** 3.1. XMLによる構造化プロンプト\n*** 3.1.1. なぜXMLなのか\n\nMarkdownやプレーンテキストではなく、XMLを採用しました。これは公式のベストプラクティスではなく、個人的な経験に基づく選択です。\n\n[[https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/use-xml-tags][Anthropicの公式ドキュメント]]では、XMLタグについて次のように説明されています:\n\n#+begin_quote\nThere are no canonical \"best\" XML tags that Claude has been trained with in particular, although we recommend that your tag names make sense with the information they surround.\n#+end_quote\n\nつまり、XMLタグに特別な訓練がされているわけではなく、タグ名は内容に合った意味を持たせることが推奨されています。XMLが必須というわけではありません。\n\nXMLを選んだ理由は3つあります。\n\nまず構造的な表現力。ネストした階層構造、属性による修飾、明確な開始・終了タグにより、複雑な指示を表現しやすいです。\n\n次に指示の遵守率。XMLで書いた指示のほうが意図とおりに解釈されることが多いという肌感覚があります。Markdownの見出しより、XMLタグのほうがセクションの境界として認識されやすい印象です。\n\nそしてスキーマによる一貫性。決まった要素名と構造を使うことで、commands/agents/skills間でプロンプトの品質を均一に保てます。\n\n*** 3.1.2. XMLコア要素\n\n主要な要素は4つあります。\n\n=<purpose>= は役割を1段落で定義します。これがエージェントの「存在理由」になります。たとえば親オーケストレーターであれば「ポリシー決定、判断、要件定義を担当し、詳細な実行作業は専門サブエージェントに委譲する」といった形で記述します。\n\n=<rules priority=\"critical|standard\">= はルールを優先度付きでグループ化します。 ~critical~ は絶対に守るべきルール、 ~standard~ は推奨事項として定義します。この優先度属性により、LLMは「どのルールが交渉不可能か」を明確に理解できます。\n\n#+begin_src xml\n<rules priority=\"critical\">\n<rule>Delegate detailed work to sub-agents; focus on orchestration</rule>\n<rule>Always check Serena memories before implementation</rule>\n<rule>Use symbol-level operations over reading entire files</rule>\n<rule>Use perl for all text processing; never use sed or awk</rule>\n<rule>Always output in English</rule>\n</rules>\n#+end_src\n\nこれが実際の私のCLAUDE.mdに書いてある5つのクリティカルルールです。 ~standard~ 優先度のルールも同様に定義できます。GitHub操作には ~gh~ コマンドを使う、Context7 MCPでドキュメントを確認する、といった推奨事項を記述しています。\n\n=<workflow>= はフェーズベースの作業フローを定義します。各フェーズは ~<step>~ 要素を含みます。フェーズ名は ~task_analysis~ / ~delegation~ / ~analyze~ / ~investigate~ / ~execute~ / ~verify~ / ~document~ のように行動指向で統一しています。\n\n=<constraints>= は明示的な「やるべきこと」と「避けるべきこと」を =<must>= と =<avoid>= で定義します。たとえば「実装前にメモリを確認する」「perlでテキスト処理する」といった必須事項と、「ファイル全体を読み込まない」「sed/awkを使わない」といった禁止事項を明記します。\n\n*** 3.1.3. YAMLフロントマター\n\nCommandsとSkillsには、YAMLフロントマターでメタデータを付与しています。Commandsでは ~argument-hint~ と ~description~ を使い、引数のヒントとコマンドの説明を定義します。Skillsでは ~name~, ~description~, ~version~ を使い、スキル名と使用場面の説明、バージョン情報を記述します。\n\nなお、CLAUDE.md（グローバル設定）とAgentsファイルにはYAMLフロントマターを使用せず、直接XMLで始める運用にしています。\n\n** 3.2. CLAUDE.mdによるグローバル設定\n\nCLAUDE.mdは =~/.claude/CLAUDE.md= に配置するグローバル設定ファイルです。ここにXML形式でプロンプトを記述し、Claude Codeの基本的な振る舞いを定義します。\n\n*** 3.2.1. グローバル vs プロジェクト\n\nClaude Codeは2種類のCLAUDE.mdを認識します。\n\n| 種類 | パス | 適用範囲 |\n|------+------+----------|\n| グローバル | =~/.claude/CLAUDE.md= | 全セッション |\n| プロジェクト | =<project>/CLAUDE.md= | 該当プロジェクトのみ |\n\n私の運用では、グローバルCLAUDE.mdに「親オーケストレーター」としての人格を定義しています。委譲のポリシー、使用するMCPツール、出力言語などの共通設定をここに集約し、プロジェクト固有の情報（技術スタック、コーディング規約など）は各プロジェクトのCLAUDE.mdに記述します。\n\n*** 3.2.2. デフォルト動作との比較\n\nカスタマイズによってClaude Codeの振る舞いは大きく変わります。\n\n| 観点 | デフォルト | カスタマイズ後 |\n|------+----------+----------------|\n| 役割 | 汎用コーディングアシスタント | Orchestration Agent |\n| 作業方針 | 自ら直接実行 | sub-agentへ委譲 |\n| ファイル操作 | ファイル全体を読み込む | シンボルレベルで操作 |\n| テキスト処理 | sed/awkを使用 | perl強制 |\n| 出力言語 | 入力言語に依存 | 英語に統一 |\n| 知識管理 | セッション内で完結 | Serenaメモリを参照 |\n\nデフォルトは「何でも自分でやる」汎用アシスタントです。カスタマイズ後は「方針を決めて専門家に任せる」オーケストレーターになります。\n\n* 4. マルチエージェント構成の実践\n\n私の設定の最大の特徴は、Claude Codeをマルチエージェントシステムとして扱っている点です。Anthropicも[[https://www.anthropic.com/engineering/multi-agent-research-system][マルチエージェントリサーチシステム]]や[[https://www.anthropic.com/engineering/claude-code-best-practices][Claude Codeのベストプラクティス]]で、オーケストレーター・ワーカーパターンの有効性を示しています。\n\n** 4.1. 階層構造の概要\n\n[[file:../../static/images/CC3ED851-5E06-4A5C-BC6A-1DEF112BE45E.png]]\n\n#+begin_src mermaid :exports none\n  graph TD\n      A[CLAUDE.md<br/>Parent Orchestration] --> B[Commands]\n      B --> C[\"/ask\"]\n      B --> D[\"/define\"]\n      B --> E[\"/execute\"]\n      B --> F[\"/feedback\"]\n\n      C --> G[Agents]\n      D --> G\n      E --> G\n      F --> G\n\n      G --> H[design]\n      G --> I[database]\n      G --> J[security]\n      G --> K[test]\n      G --> L[...]\n\n      H --> M[Skills]\n      I --> M\n      J --> M\n      K --> M\n\n      M --> N[serena-usage]\n      M --> O[context7-usage]\n      M --> P[nix-ecosystem]\n      M --> Q[...]\n#+end_src\n\n各階層の役割を整理します。CLAUDE.mdは親オーケストレーターとして方針決定と委譲を担います。Commandsはユーザーインターフェースとして特定タスクの起点となります。Agentsはdesign、security、testなど専門領域のエキスパートとして機能します。Skillsはnix-ecosystem、serena-usageなどドメイン知識ベースを提供します。\n\nこのマルチエージェント構成には大きなメリットがあります。まず関心の分離により、各エージェントは自分の専門領域に集中できます。セキュリティエージェントはセキュリティだけ、テストエージェントはテストだけを考えればよいのです。次に並列実行が可能になり、独立したタスクを同時に処理できます。また知識の再利用として、Skillsは複数のAgentsから参照されるため、同じ知識を何度も定義する必要がありません。そして保守性の向上により、1つのエージェントの変更が他に影響しないという利点があります。\n\n** 4.2. コマンドによるワークフロー定義\n\nClaude Codeのcommandは、AIエージェントの振る舞いを定義する重要な設定です。私はカスタムコマンドを設計し（[[https://github.com/takeokunn/nixos-configuration/tree/af95701a89e8128ba000dee3062eefa33c7d2001/home-manager/programs/claude-code/commands][commands/ディレクトリ参照]]）、「オーケストレーションパターン」と「Readonlyファースト哲学」という2つの設計思想に基づいて構築しています。\n\n*** 4.2.1. Readonlyファースト哲学\n\n「まず調べて、実行計画を立ててから、手を動かす」がReadonlyファースト哲学の核心です。\n\nAIに作業を任せる際、もっとも危険なのは「調査しているつもりが、いつの間にかコードを変更していた」という事故です。この問題を根本から解決するため、私のワークフローではコマンドを「調査系」と「実行系」に完全分離しています。\n\n=/define= （要件定義）、 =/ask= （質問・調査）、 =/bug= （原因調査）の3つは、どれだけ深く調べても絶対にファイルを変更しません。各コマンドのプロンプトで =<rules priority=\"critical\">= として「Never change, create, or delete files」と明示的に禁止しているからです。調査結果をもとに実行計画を立て、その計画を =/execute= に渡すという流れになります。\n\nコードを変更できるのは =/execute= だけ。この明確な境界線があるからこそ、安心して「とことん調べて」とAIに指示できるのです。\n\n*** 4.2.2. コマンド一覧\n\n| Command     | Purpose        | Mode       | Key Agents                                 |\n|-------------+----------------+------------+--------------------------------------------|\n| =/define=   | 要件定義        | Read-only  | explore, design, database, general-purpose |\n| =/ask=      | 質問・調査      | Read-only  | explore, design, performance               |\n| =/bug=      | 原因調査        | Read-only  | quality-assurance, explore                 |\n| =/execute=  | タスク実行      | Read-write | カスタム + インライン                        |\n| =/feedback= | コードレビュー   | Read-only  | モードにより動的に選択                        |\n| =/markdown= | ドキュメント出力 | Write-only | なし（フォーマットのみ）                      |\n\n=/execute= は2種類のエージェントを活用します。カスタムエージェントは =agents/= ディレクトリで定義された専門エージェントで、複雑なタスクを担当します。一方、インラインエージェントはコマンド内で定義されたタスク特化型です。quality / security / test / refactor / docs / review / debug / performance / clean / error-handling / migration / database / infrastructure / ci-cd / observability / git / memory といった軽量な処理を担当します。\n\n*** 4.2.3. ワークフロー\n\nワークフローは4つのフェーズで構成されています。Investigation Phaseでは =/define= / =/ask= / =/bug= で調査します（読み取り専用）。Execution Phaseでは =/execute= でタスクを実行します。Quality Phaseでは =/feedback= でコードレビューし、問題があれば =/execute= に戻ります。Output Phaseでは =/markdown= でドキュメントを出力します。このサイクルを回すことで、品質を担保しながら開発を進められます。\n\n[[file:../../static/images/2D573FE7-304B-4379-B3C5-E0542F4DA022.png]]\n\n#+begin_src mermaid :exports none\nflowchart TD\n    subgraph Investigation[\"Investigation Phase (Read-Only)\"]\n        define[\"/define<br/>Requirements Definition\"]\n        ask[\"/ask<br/>Q&A / Research\"]\n        bug[\"/bug<br/>Root Cause Analysis\"]\n    end\n\n    subgraph Execution[\"Execution Phase (Read-Write)\"]\n        execute[\"/execute<br/>Task Execution\"]\n    end\n\n    subgraph Quality[\"Quality Phase (Read-Only)\"]\n        feedback[\"/feedback<br/>Code Review\"]\n    end\n\n    subgraph Output[\"Output Phase (Write-Only)\"]\n        markdown[\"/markdown<br/>Document Output\"]\n    end\n\n    %% Main workflow transitions\n    define --> execute\n    ask --> execute\n    bug --> execute\n\n    execute --> feedback\n    feedback -->|\"Issues Found\"| execute\n    feedback -->|\"Approved\"| markdown\n\n    %% Optional review paths from Investigation Phase\n    define -->|\"Optional Review\"| feedback\n    ask -->|\"Optional Review\"| feedback\n    bug -->|\"Optional Review\"| feedback\n\n    %% Alternative paths (direct to output)\n    define --> markdown\n    ask --> markdown\n    bug --> markdown\n#+end_src\n\n*** 4.2.4. 代表的なコマンド: /define\n\n=/define= は実装前に詳細な要件を定義するコマンドです。技術的制約、設計方針、仕様を明確化します。クリティカルルールとして「ファイルを変更しない」「コードを実装しない」「技術的に不可能な要求を明確に識別する」を設定しています。\n\nWorkflowは「Analyze → Investigate → Clarify → Verify → Document」の5フェーズで構成し、「要件ドキュメント」と「タスク分解」の2つの成果物を生成します。このコマンドを使うことで、実装を始める前に要件を整理でき、手戻りを減らせるようになりました。\n\n以下は実際のプロンプト構造です（簡略版）:\n\n#+begin_src xml\n<purpose>\nConduct detailed requirements definition before implementation,\nclarifying technical constraints, design policies, and specifications.\n</purpose>\n\n<rules priority=\"critical\">\n<rule>Never modify, create, or delete files</rule>\n<rule>Never implement code; requirements definition only</rule>\n<rule>Clearly identify technically impossible requests</rule>\n</rules>\n\n<workflow>\n<phase name=\"analyze\">\n<step>What is the user requesting?</step>\n<step>What technical constraints exist?</step>\n</phase>\n<phase name=\"investigate\">\n<step>Delegate to explore agent: find relevant files</step>\n<step>Delegate to design agent: evaluate architecture</step>\n</phase>\n<phase name=\"clarify\">\n<step>Score questions by: design branching, irreversibility (1-5)</step>\n<step>Present high-score questions first</step>\n</phase>\n<phase name=\"document\">\n<step>Create comprehensive requirements document</step>\n<step>Break down tasks for /execute handoff</step>\n</phase>\n</workflow>\n\n<agents>\n<agent name=\"explore\" subagent_type=\"explore\" readonly=\"true\"/>\n<agent name=\"design\" subagent_type=\"design\" readonly=\"true\"/>\n<agent name=\"database\" subagent_type=\"database\" readonly=\"true\"/>\n</agents>\n#+end_src\n\nポイントは =readonly=\"true\"= 属性です。サブエージェントにも読み取り専用を強制することで、調査フェーズ全体での安全性を担保しています。これがあるおかげで、「調べてたらうっかりファイル消しちゃいました」みたいな事故を防げます。\n\n** 4.3. 専門エージェントの設計\n\nagentsディレクトリには複数の専門エージェントを定義しています（[[https://github.com/takeokunn/nixos-configuration/tree/af95701a89e8128ba000dee3062eefa33c7d2001/home-manager/programs/claude-code/agents][agents/ディレクトリ参照]]）。各エージェントはSingle Responsibility Principleに基づき、1つのドメインに特化したエキスパートとして振る舞います。\n\n*** 4.3.1. 設計思想\n\nエージェント設計の核心は3点あります。\n\nまずドメイン特化です。各エージェントは自分の専門領域のみを担当します。セキュリティエージェントはセキュリティだけ、テストエージェントはテストだけを扱います。この明確な責任分担により、専門性の高い出力が得られます。\n\n次にワークフローの統一があります。全エージェントが「analyze → （domain-specific phases） → report」という基本構造を持ちます。フェーズ数はエージェントにより4〜5で異なりますが（例: security agentは「analyze → gather → scan → remediate → report」、design agentは「analyze → investigate → synthesize → document」）、最初の分析と最後の報告という骨格は共通です。これにより振る舞いが予測可能になり、どのエージェントを使っても一貫した体験が得られます。\n\nそして安全性のガードレールです。 =<rules priority=\"critical\">= で定義した絶対ルールにより、危険な操作を防止しています。AIに任せるからこそ、明確な制約が必要なのです。\n\n*** 4.3.2. エージェント例\n\n| Agent           | Purpose                    | Key Tools                              |\n|-----------------+----------------------------+----------------------------------------|\n| code-quality    | 複雑度分析・リファクタリング | Serena （symbol analysis）, Bash （lint）  |\n| database        | DB設計・クエリ最適化       | Serena, Bash （EXPLAIN）                 |\n| design          | アーキテクチャ評価・見積り | Serena （dependency）, Context7          |\n| devops          | CI/CD・IaC設計             | Bash, Context7                         |\n| docs            | ドキュメント生成           | Write, Serena                          |\n| git             | ブランチ戦略・リリース管理 | Bash （git）, Grep                       |\n| performance     | ボトルネック分析・最適化   | Serena, Bash （profiling）               |\n| quality-assurance| コードレビュー・デバッグ  | Serena, Grep, Context7                 |\n| security        | 脆弱性検出・修正           | Serena, Grep, Bash （audit）, Context7   |\n| test            | テスト戦略・カバレッジ     | Serena, Glob, Bash （test runner）       |\n\n*** 4.3.3. 代表的なエージェント: security agent\n\nsecurity agentは脆弱性検出・修正・依存関係監査を担当するエージェントです。認証、インジェクション攻撃、シークレット漏洩、暗号化、依存関係の脆弱性を専門としています。\n\nクリティカルルールとして「シークレット漏洩検出時は即座にアラート」「重大な脆弱性ではビルドを停止」「脆弱性の存在を結論づける前にコンテキストを確認」「既存の監査ツール（npm audit, cargo audit）を使用」を設定しています。\n\nworkflowは「analyze → gather → scan → remediate → report」の5フェーズで、特に =scan= フェーズではシークレット漏洩やインジェクション脆弱性のパターンマッチングを実行します。このエージェントのおかげで、セキュリティレビューが自動化され、見落としが減りました。\n\n以下は実際のプロンプト構造です（簡略版）:\n\n#+begin_src xml\n<purpose>\nExpert security agent for vulnerability detection, remediation, and dependency management.\nSpecializes in authentication, injection attacks, secret leakage, encryption, and dependency vulnerabilities.\n</purpose>\n\n<rules priority=\"critical\">\n<rule>Alert immediately on secret leakage detection</rule>\n<rule>Stop build on critical vulnerabilities</rule>\n<rule>Verify context before concluding vulnerability exists</rule>\n<rule>Use existing audit tools (npm audit, cargo audit)</rule>\n</rules>\n\n<workflow>\n<phase name=\"analyze\">\n<step>What are the high-risk files/areas?</step>\n<step>What authentication/authorization patterns exist?</step>\n<step>Are there hardcoded secrets?</step>\n</phase>\n<phase name=\"gather\">\n<step>Identify high-risk files, check dependencies</step>\n</phase>\n<phase name=\"scan\">\n<step>Pattern match secrets/injections, run audits</step>\n</phase>\n<phase name=\"remediate\">\n<step>Auto-fix or report, verify changes</step>\n</phase>\n<phase name=\"report\">\n<step>Summary by severity with fixes</step>\n</phase>\n</workflow>\n\n<examples>\n<example name=\"secret_scan\">\n<input>Scan for hardcoded API keys</input>\n<process>\n1. Search for API key patterns with serena search_for_pattern\n2. Check config files for hardcoded values\n3. Verify if values are actual secrets or placeholders\n</process>\n<output>\n{\n  \"status\": \"warning\",\n  \"summary\": \"2 hardcoded API keys detected\",\n  \"details\": [{\"error\": \"SEC002\", \"location\": \"/config.js:15\", \"fix_suggestion\": \"Use process.env.API_KEY\"}],\n  \"next_actions\": [\"Migrate to env vars\"]\n}\n</output>\n</example>\n</examples>\n\n<error_codes>\n<code id=\"SEC001\" condition=\"Critical vulnerability\">Stop build, alert</code>\n<code id=\"SEC002\" condition=\"Secret leakage\">Alert immediately</code>\n<code id=\"SEC003\" condition=\"Vulnerable dependency\">Recommend update</code>\n</error_codes>\n#+end_src\n\nポイントは =<examples>= 要素です。入力・処理手順・出力の3つを明示することで、エージェントの期待動作を具体的に伝えています。「こういうときはこう動いてね」というお手本を見せてあげるイメージです。また、 =<error_codes>= でエラー種別を定義し、状況に応じた適切な対応を指示しています。\n\n** 4.4. スキルによる知識ベース構築\n\nSkillsはドメイン知識ベースとして機能し、複数のAgentsから参照される共有リソースです。Agentsが「専門領域のエキスパート」なら、Skillsは「ドメイン知識の辞書」といえます。\n\n*** 4.4.1. Skillの役割と位置づけ\n\n階層構造は「Commands → Agents → Skills」となっています。Commandsがユーザーインターフェースとして機能し、Agentsを呼び出します。Agentsは専門領域のタスクを実行し、Skillsを参照します。Skillsはドメイン知識を提供し、複数のAgentsから参照されます。\n\nこの設計の重要なポイントは、Skillsが状態を持たない純粋な知識ベースであることです。Agentsがタスクを実行する際に必要な「パターン」「ベストプラクティス」「アンチパターン」を提供し、Agents自身は実行に集中できます。\n\n*** 4.4.2. スキルカテゴリ一覧\n\n現在複数のスキルを4カテゴリに分類して定義しています（[[https://github.com/takeokunn/nixos-configuration/tree/af95701a89e8128ba000dee3062eefa33c7d2001/home-manager/programs/claude-code/skills][skills/ディレクトリ参照]]）。\n\nツール連携では、serena-usageとcontext7-usageでMCPの使い方を定義しています。言語・インフラエコシステムでは、Nix、TypeScript、Go、Rust、Common Lisp、Emacs Lispの6言語に加え、aws-ecosystemでAWS CLI/Terraformのパターンもカバーしています。私が日常的に使う技術スタックを網羅しているため、どの環境で開発してもClaude Codeが適切な知識を持って対応できます。ワークフローでは、investigation-patterns、execution-workflow、requirements-definition、testing-patternsで作業パターンを定義しています。ドキュメントでは、technical-documentationとtechnical-writingで文書作成を支援しています。\n\n*** 4.4.3. スキルの構造例: investigation-patterns\n\ninvestigation-patternsスキルを例に構造を説明します。 =<purpose>= でスキルの目的（コードベース調査とデバッグのための体系的パターン提供）を定義し、 =<patterns>= で具体的なパターン（evidence_collection、five_whysなど）を記述します。\n\n重要なのは =<best_practices>= と =<anti_patterns>= の組み合わせです。「ファイル:行番号の参照を必ず提示する」「調査結果の信頼度とカバレッジを評価する」といったベストプラクティスと、「証拠が不十分なまま推測しない」といったアンチパターンを明示することで、LLMの行動を両面から制約しています。\n\n以下は実際のプロンプト構造です（簡略版）:\n\n#+begin_src xml\n<purpose>\nProvide systematic patterns for codebase investigation and debugging,\nensuring evidence-based analysis with proper confidence assessment.\n</purpose>\n\n<patterns>\n<pattern name=\"evidence_collection\">\n<description>Collect evidence systematically using appropriate tools</description>\n<example>\nfind_symbol: Locate specific symbols by name\nget_symbols_overview: Understand file structure\nfind_referencing_symbols: Trace dependencies\nsearch_for_pattern: Find patterns across codebase\n</example>\n</pattern>\n\n<pattern name=\"five_whys\">\n<description>Ask \"why\" repeatedly to drill to root cause</description>\n<example>\nWhy did the server crash? - Out of memory\nWhy out of memory? - Connection pool exhausted\nWhy exhausted? - Connections not being released\nWhy not released? - Exception bypasses cleanup\nRoot cause: Missing try-finally for connection release\n</example>\n</pattern>\n</patterns>\n\n<concepts>\n<concept name=\"evidence_standards\">\n<description>Standards for collecting and reporting evidence</description>\n<example>\nCitation: Always provide file:line references (path/to/file.ext:line_number)\n\nConfidence levels:\n- 90-100: Direct code evidence, explicit documentation\n- 70-89: Strong inference from multiple sources\n- 50-69: Reasonable inference with some gaps\n- 0-49: Speculation, insufficient evidence\n</example>\n</concept>\n</concepts>\n\n<anti_patterns>\n<avoid name=\"speculation\">\n<description>Guessing or making claims when evidence is insufficient</description>\n<instead>Clearly state confidence levels and information gaps</instead>\n</avoid>\n\n<avoid name=\"uncited_claims\">\n<description>Making claims without file:line references</description>\n<instead>Always provide file:line citations using format path/to/file.ext:line_number</instead>\n</avoid>\n</anti_patterns>\n\n<best_practices>\n<practice priority=\"critical\">Always provide file:line references for all findings</practice>\n<practice priority=\"critical\">Rate confidence and coverage metrics for all investigation results</practice>\n<practice priority=\"high\">Use Serena symbol tools before reading entire files</practice>\n<practice priority=\"high\">Document information gaps and unclear points</practice>\n</best_practices>\n#+end_src\n\nポイントは =<patterns>= と =<concepts>= で「何をするか」を定義し、 =<anti_patterns>= と =<best_practices>= で「どのように振る舞うか」を制約している点です。特に =<avoid>= と =<instead>= の組み合わせが便利で、「これはダメ」だけじゃなく「代わりにこうして」まで教えてあげられます。\n\nマルチエージェント構成の全体像を理解したところで、次章ではこのシステムをさらに強化するMCP Serverについて解説します。\n\n* 5. MCPによる機能拡張\n\n[[https://modelcontextprotocol.io/][MCP (Model Context Protocol)]] はAnthropicが策定したオープンプロトコルで、AIモデルと外部ツール・データソースを接続するための標準仕様です。Claude Codeは複数のMCP Serverを同時に利用でき、これにより機能を大幅に拡張できます。\n\n** 5.1. なぜ3つのMCPサーバなのか\n\n私は [[https://github.com/upstash/context7][Context7]]、[[https://github.com/openai/codex][Codex]]、[[https://github.com/oraios/serena][Serena]] という3つのMCPサーバを組み合わせています。Context7とSerenaはMCP Server、CodexはMCPクライアントとして機能し、それぞれが異なるギャップを埋めています。どれか1つが欠けても開発体験が損なわれます。\n\n*** 5.1.1. 各サーバが埋めるギャップ\n\nLLMの訓練データには期限があります。最新のReact 19のAPIや、先月リリースされたライブラリのドキュメントをClaude Codeは知りません。この問題を解決するのが[[https://upstash.com/][Upstash社]]が提供する *Context7* です。npmやGitHubから最新のドキュメントをリアルタイムで取得し、常に最新の情報に基づいたコード生成を可能にします。\n\nプロジェクトには固有のパターンや規約があります。これを毎回説明するのは非効率です。[[https://github.com/oraios][Oraios社]]が開発した *Serena* は、シンボルレベルのコード操作と永続的なメモリ機能を提供します。LSPを通じて30以上の言語をサポートしており、一度覚えたプロジェクトの規約を次回以降も記憶してくれます。\n\nClaude Code自身もコードを生成できますが、複雑なリファクタリングやボイラープレート生成では専用ツールが欲しくなることがあります。[[https://openai.com][OpenAI社]]が提供する *Codex* は[[https://developers.openai.com/codex/mcp/][MCPクライアントとして他のMCP Serverと連携]]でき、コード生成に特化したエンジンとして活用できます。\n\n*** 5.1.2. ツール優先度の階層\n\n私のワークフローでは、ツールの使用に明確な優先度を設けています。\n\n[[file:../../static/images/948E82A2-58AB-41CB-AD87-1DF1081C5C17.png]]\n\n#+begin_src mermaid :exports none\n  graph LR\n      subgraph \"ツール優先度（低コスト → 高機能）\"\n          A[Basic Tools<br/>Read/Edit/Write] --> B[Serena<br/>シンボル操作/メモリ]\n          B --> C[Context7<br/>外部ドキュメント]\n          C --> D[Codex<br/>コード生成]\n      end\n#+end_src\n\nこの優先度には理由があります。Priority 1のBasic Tools（Read/Edit/Write）はもっとも軽量で、単純なファイル操作には十分です。Priority 2のSerenaは、シンボル単位の操作でトークンを節約しながらコードを探索・編集できます。Priority 3のContext7は、外部ライブラリの最新ドキュメントが必要な場合にのみ使用します。Priority 4のCodexは、複雑なコード生成タスクに限定して使用し、調査や分析には使いません。\n\n*** 5.1.3. Nix設定例\n\n[[https://github.com/natsukium/mcp-servers-nix][mcp-servers-nix]]を使用した宣言的なMCP Server設定を紹介します（[[https://github.com/takeokunn/nixos-configuration/blob/af95701a89e8128ba000dee3062eefa33c7d2001/home-manager/programs/claude-code/default.nix#L131-L142][実際の設定参照]]）。\n\n#+begin_src nix\nmcpServers =\n  (mcp-servers-nix.lib.evalModule pkgs {\n    programs = {\n      context7.enable = true;\n      codex.enable = true;\n      serena = {\n        enable = true;\n        context = \"claude-code\";\n        enableWebDashboard = false;\n      };\n    };\n  }).config.settings.servers;\n#+end_src\n\n=context = \"claude-code\"= はSerenaの動作モードを指定するパラメータで、Claude Codeとの統合に最適化された設定が適用されます。\n\n** 5.2. 統合ワークフロー\n\n3つのMCP Serverは独立して動くのではなく、ワークフローの各フェーズで連携します。次のシーケンス図は、ユーザーからの実装依頼が完了するまでの流れを示しています。\n\n[[file:../../static/images/67C913D9-DA99-4696-994B-AAE6FD9E486A.png]]\n\n#+begin_src mermaid :exports none\n  sequenceDiagram\n      participant User\n      participant Claude as Claude Code\n      participant C7 as Context7\n      participant Codex\n      participant Serena\n\n      User->>Claude: \"ライブラリYを使って機能Xを実装して\"\n      Claude->>C7: resolve-library-id(\"Y\")\n      C7-->>Claude: Library ID + ドキュメント\n      Claude->>Serena: find_symbol(\"related_code\")\n      Serena-->>Claude: 既存パターン\n      Claude->>Serena: read_memory(\"conventions\")\n      Serena-->>Claude: プロジェクト規約\n      Claude->>Codex: 実装を生成\n      Codex-->>Claude: 生成されたコード\n      Claude->>Serena: write_memory(\"new_pattern\")\n      Claude-->>User: 実装完了\n#+end_src\n\n*** 5.2.1. Phase 1: 外部知識取得（Context7）\n\nまずContext7で外部ライブラリの最新ドキュメントを取得します。 =resolve-library-id= でパッケージ名からライブラリIDを解決し、 =get-library-docs= でドキュメントを取得します。 =topic= パラメータで関心領域を絞り込むこともできます。信頼スコア7-10のライブラリを優先することで、信頼性の高いドキュメントを参照できます。\n\n*** 5.2.2. Phase 2: 内部知識取得（Serena）\n\n次にSerenaでプロジェクト固有のパターンを取得します。 =find_symbol= で関連するコード要素を探索し、 =read_memory= でプロジェクトの規約やベストプラクティスを読み込みます。 =find_referencing_symbols= で影響範囲を事前確認することで、安全にコードを変更できます。\n\nSerenaのツールは4カテゴリに分かれます。シンボル検索では =get_symbols_overview= / =find_symbol= / =find_referencing_symbols= でコード要素を探索します。パターン検索では =search_for_pattern= で正規表現による横断検索をします。コード編集では =replace_symbol_body= / =insert_before_symbol= / =insert_after_symbol= / =rename_symbol= でシンボル単位を編集します。メモリでは =list_memories= / =read_memory= / =write_memory= / =edit_memory= / =delete_memory= で知識を永続化します。\n\n*** 5.2.3. Phase 3: 実装（Codex）\n\n外部知識と内部知識が揃ったら、Codexでコードを生成します。 =codex()= で会話を開始し、 =codex-reply()= で継続します。適切な使用場面は、新規ファイル・関数の生成、複雑なリファクタリング、ボイラープレートコードの生成です。\n\n経験的に、Codexはコード生成が得意です。Claude Codeも優れたコード生成能力を持っていますが、Codexに任せたほうがきれいなコードが出てくることが多いと感じています。特にボイラープレートや定型的なコード生成では、その差が顕著です。\n\n重要な制約として、調査・分析にはCodexを使わず、1回の呼び出しで1つの明確なタスクに限定し、マルチファイル編集は避けるようにしています。\n\n*** 5.2.4. Phase 4: 知識永続化（Serena）\n\n実装完了後、新たに発見したパターンや規約を =write_memory= でSerenaに保存します。次回以降のセッションでも同じ知識を再利用できるため、プロジェクトの規約を毎回説明する手間がなくなります。\n\nこの4フェーズの連携により、最新のベストプラクティスを参照しつつ、プロジェクト固有の規約に準拠したコードを生成し、学習した知識を蓄積していけます。\n\nMCP Serverによる機能拡張を理解したところで、次章ではhome-managerによる宣言的管理と安全性の確保について解説します。\n\n* 6. 運用と安全性\n\n本章では、Claude Code設定の宣言的管理と、安全性を担保するための仕組みについて解説します。\n\n** 6.1. home-managerによる宣言的管理\n\nClaude Codeの設定はhome-managerで宣言的に管理しています。 =programs.claude-code= モジュールを中心に、CLAUDE.md、agents/、commands/、skills/、hooks/、scripts/ というディレクトリ構成で整理しています。\n\n#+begin_src nix\nprograms.claude-code = {\n  enable = true;\n  package = nodePkgs.\"@anthropic-ai/claude-code\";\n  memory.source = ./CLAUDE.md;\n\n  settings = {\n    theme = \"dark\";\n    autoUpdates = false;\n    autoCompactEnabled = true;\n    enableAllProjectMcpServers = true;\n    outputStyle = \"Explanatory\";\n  };\n\n  agents = { ... };\n  commands = { ... };\n  skills = { ... };\n  hooks = { ... };\n  mcpServers = { ... };\n};\n#+end_src\n\nagents/commands/skills/hooksの各項目は =builtins.readFile= でMarkdownファイルを読み込む形式を採用しています。たとえば =agents = { code-quality = builtins.readFile ./agents/code-quality.md; }= のように記述します。プロンプトの内容をMarkdownで記述できるため可読性が高く、Nixの評価時に文字列として埋め込まれるためファイル単位でのdiffも取りやすくなります。\n\nこの宣言的アプローチの最大の利点は再現性です。設定をGitで管理し、 =home-manager switch= 一発で同一の環境を任意のマシンに展開できます。\n\n** 6.2. hooksによるポリシー強制\n\nhooksはClaude Codeのツール実行ライフサイクルに介入する仕組みです。\n私は2種類のhooksを設定しています。タスク完了通知とコマンドバリデーションです。\n\n*** 6.2.1. hooksの種類\n\n[[https://code.claude.com/docs/en/hooks][公式ドキュメント]]では10種類のhookイベントが定義されていますが、私が使用しているのは4種類です。 =PreToolUse= はツール実行前に発火し、バリデーションやコマンド検証に使用します。 =PostToolUse= はツール実行後に発火し、ログ記録や後処理に使用します。 =Stop= はセッション終了時に発火し、通知やクリーンアップに使用します。 =Notification= は通知イベントで、外部連携に使用します。\n\nhookスクリプトの終了コード規約として、 =exit 0= は処理を許可し、 =exit 2= は処理をブロックします（stderrがエラーメッセージとして表示されます）。\n\n*** 6.2.2. enforce-perl hook: コマンドバリデーション\n\nCLAUDE.mdで定義した「perlでテキスト処理」ルールを強制するバリデーションhookを紹介します（[[https://github.com/takeokunn/nixos-configuration/blob/af95701a89e8128ba000dee3062eefa33c7d2001/home-manager/programs/claude-code/hooks/enforce-perl.sh][hooks/enforce-perl.sh]]）。\n\n#+begin_src bash\n#!/bin/bash\nset -euo pipefail\n\ninput=$(cat)\ntool_name=$(echo \"$input\" | jq -r '.tool_name // \"\"')\ncommand=$(echo \"$input\" | jq -r '.tool_input.command // \"\"')\n\nif [[ $tool_name != \"Bash\" ]] || [[ -z $command ]]; then\n  exit 0\nfi\n\n# sed/awk使用を検出してブロック\nif echo \"$command\" | grep -qE '\\b(sed|awk)\\b'; then\n  cat >&2 <<'EOF'\n❌ sed/awk detected - Use perl instead\n\nExamples:\n  ❌ sed 's/foo/bar/g' file.txt\n  ✅ perl -pe 's/foo/bar/g' file.txt\nEOF\n  exit 2  # Block the command\nfi\n\nexit 0  # Allow\n#+end_src\n\n=\\b(sed|awk)\\b= の正規表現でワードバウンダリを指定し、 =sediment= のような誤検出を防いでいます。「perlを使え」とCLAUDE.mdに書いてあるのにsedを使ってきたら、hookがブロックして「perlにしてね」と返してくれます。\n\n** 6.3. permissions と statusline\n*** 6.3.1. permissions: 多層防御\n\npermissionsは、Claude Codeが実行できるコマンドを制限するセーフティネットです。Defense in Depth（多層防御）の考え方で、サンドボックス（第1層）、permissions deny（第2層）、hooks validation（第3層）の3層構造で保護しています。\n\n危険なコマンドを6つのカテゴリに分類して禁止しています。ファイル破壊（ =rm -rf /= など）、システムコマンド（ =shutdown= / =reboot= ）、ディスク操作（ =dd= / =mkfs= ）です。さらにプロセス制御（ =killall= / =pkill= ）、ネットワークリスナー（ =nc -l= ）、権限昇格（ =sudo rm= / =chmod 777= ）も禁止しています。\n\n*** 6.3.2. statusline: セッション状態の可視化\n\nstatuslineはClaude Codeのセッション状態をリアルタイムで可視化する機能です（[[https://github.com/takeokunn/nixos-configuration/blob/af95701a89e8128ba000dee3062eefa33c7d2001/home-manager/programs/claude-code/scripts/statusline.sh][scripts/statusline.sh]]）。モデル名、カレントディレクトリ、Gitブランチ、トークン使用量と割合を表示します。\n\nトークン使用率に応じて色を変えることで、コンパクション発生前に警告を出せます。70%未満は緑（十分な余裕あり）、70-89%は黄色（注意が必要）、90%以上は赤（コンパクション間近）で表示されます。\n\nここまでの章で、プロンプト設計、マルチエージェント構成、MCPによる機能拡張、そして運用と安全性について解説してきました。次章では、運用して得られた結果と所感を共有します。\n\n* 7. 得られた結果・所感\n\nこのワークフローを使い始めて、開発体験が明らかに変わりました。\n\n一番大きいのは、Claude Codeの振る舞いが予測可能になったことです。以前は「今日はどんな形式で返ってくるかな」と毎回ドキドキしていましたが、XMLで構造化したプロンプトと専門エージェントへの委譲により、期待とおりの出力が得られるようになりました。\n\nセキュリティレビューをお願いすれば、ちゃんとセキュリティの観点だけでレビューしてくれます。コードスタイルの指摘が混在することもなくなりました。これが地味に嬉しい。\n\n=/define= → =/execute= → =/feedback= というフローも気に入っています。調査と実装が明確に分離されているので、「調べてたらいつの間にかファイルが変わってた」という事故がなくなりました。安心して「とことん調べて」といえるのは大きい。\n\n一方で、Serenaが本当に必要なのかは正直まだわかりません。シンボルレベルの操作でトークン効率が上がるとは書きましたが、Claude Code標準のGlob/Grep/Readでも十分な気がしています。LSP設定やオンボーディングの手間を考えると、その複雑さに見合うリターンがあるのか。今後の運用で見極めていきたいところです。\n\n* 8. おわりに\n\n私のClaude Codeワークフローを紹介しました。\n\n「セキュリティレビューなのにコードスタイルの指摘ばかり」という不満から始まった試行錯誤が、気づけばマルチエージェントシステムになっていました。ここまで作り込むとは思っていませんでしたが、AIツールの設定をソフトウェアプロジェクトのように育てていくのは楽しいものです。\n\nやりたいことはまだまだあります。プロンプト入力の英語統一、Context7とSerenaの使い分け基準の明確化、クロスプロジェクトでの知識共有など。\n\n本記事で紹介した設定は[[https://github.com/takeokunn/nixos-configuration/tree/af95701a89e8128ba000dee3062eefa33c7d2001/home-manager/programs/claude-code][GitHubリポジトリ]]で公開しています。Nixユーザーの方はそのまま参考にできるはずです。[[https://code.claude.com/docs/en/overview][公式ドキュメント]]と合わせてどうぞ。\n",
  "backlinks": []
}